{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: The DFT and FFT\n",
    "## Due Date: 4/6 @ 11:59pm on Compass\n",
    "\n",
    "In the last lab, we explored the Discrete-Time Fourier Transform (DTFT) and the frequency response of LSI systems. However, we know that it is impossible to hold an entire DTFT in computer memory since the DTFT of a signal has infinitely many points! We will discuss the Discrete Fourier Transform (DFT) and Fast Fourier Transform (FFT) in this lab as the practical implementations of the DTFT and consider some of the limitations and considerations when using the DFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Fourier Transform\n",
    "\n",
    "The Discrete Fourier Transform (DFT) is the discretized version of the DTFT. Sounds weird, right? Isn't the DTFT already discrete? It's in the name! But recall that the DTFT is a continuous function: it has infinitely many points to represent frequency content from $-\\pi$ to $\\pi$. The DFT is just a resampling of the DTFT. In other words, the DFT picks a finite number of equally spaced points in the DTFT for representation.\n",
    "\n",
    "More concretely, the DFT is computed as follows: \n",
    "\n",
    "$$\n",
    "X[k] = \\sum_{n=0}^{N-1}x[n]e^{-j\\frac{2\\pi k}{N}n}, \\quad 0\\leq k\\leq N-1.\n",
    "$$\n",
    "And the inverse DFT is given by:\n",
    "\n",
    "$$\n",
    "x[n] = \\frac{1}{N}\\sum_{k=0}^{N-1}X[k]e^{j\\frac{2\\pi k}{N}n}, \\quad 0\\leq n\\leq N-1\n",
    "$$\n",
    "The DFT has $N$ \"frequency bins\" differentiated by our frequency index $k$. These are the samples we take from the DTFT. Perhaps a more intuitive formulation with respect to the DTFT makes these bins more obvious:\n",
    "\n",
    "$$\n",
    "\\omega_k = \\frac{2\\pi k}{N},\n",
    "$$\n",
    "\n",
    "$$\n",
    "X[k] = \\sum_{n=0}^{N-1}x[n]e^{-j\\omega_k n}, \\quad 0\\leq k\\leq N-1.\n",
    "$$\n",
    "\n",
    "This representation explicitly shows that we try to capture $N$ equally spaced frequencies between 0 to $2\\pi$ (same as $-\\pi$ to $\\pi$ by periodicity of DTFT) with the DFT.\n",
    "\n",
    "### The Linear Algebra Intuition\n",
    "\n",
    "The DFT gives an important insight into how we can use linear algebra or vectorize our systems to perform common signal processing operations. Consider our second formulation of the DFT. Suppose we fix $k$ to be one value $k_0$. The second formulation tells us that\n",
    "\n",
    "$$\n",
    "X[k_0] = \\sum_{n=0}^{N-1}x[n]e^{-j\\omega_{k_0} n}.\n",
    "$$\n",
    "\n",
    "There is helpful notation that can be introduced here using something call the \"twiddle factor\" (great name, right?). Different conventions exist for the twiddle factor, but we will opt for the one most consistent with your ECE 310 textbook. Consider the following notation for the twiddle factor $W$:\n",
    "\n",
    "$$\n",
    "W = e^{-j2\\pi}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_N = e^{-j\\frac{2\\pi}{N}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_N^{k} = e^{-j\\frac{2\\pi k}{N}}\n",
    "$$\n",
    "\n",
    "If we return to our expression for $X[k_0]$, we see that all we are doing at frequency $\\omega_{k_0}$ is summing the product of each entry in the signal and some complex exponential. This is the same thing as taking an inner product (dot product) between the signal and the complex exponential rotating at frequency $w_{k_0}$! Thus,\n",
    "\n",
    "$$\n",
    "e^{-j\\omega_{k_0}n} = [e^{-j\\omega_{k_0}*(0)},e^{-j\\omega_{k_0}*(1)},\\ldots,e^{-j\\omega_{k_0}*(N-1)}] = [W_N^{k_0*0},W_N^{k_0*1},W_N^{k_0*2},\\ldots,W_N^{k_0*(N-1)}]\n",
    "$$\n",
    "\n",
    "$$\n",
    "X[k_0] = \\langle W_N^{-k_0n},x[n] \\rangle = \\sum_{n=0}^{N-1}x[n]e^{-j\\omega_{k_0} n}.\n",
    "$$\n",
    "\n",
    "Note that when we take the inner product over complex numbers, we conjugate-transpose the first term by convention. For example, $\\langle x,y\\rangle = x^*y$, where $x^*$ is the transpose of $x$ and each element is complex conjugated. Thus,\n",
    "$$\n",
    "X[k_0] = \\langle W_N^{-k_0n},x[n] \\rangle = \\sum_{i=0}^{N-1}W_N^{k_0i}x[i]\n",
    "$$\n",
    "as desired.\n",
    "\n",
    "Now, recall that if the dot product between two vectors is large, they are similar. The same is true here! For each frequency, we take the dot product between our signal and a vector represented by a complex exponential rotating at a fixed frquency. The result tells us how much that fixed frequency is found in our signal. Wow. We can take one final step to make the entire DFT a matrix-vector product:\n",
    "\n",
    "$$\n",
    "X[k] = \\mathbf{W}\\vec{x}\n",
    "$$\n",
    "\n",
    "$$\n",
    "X[k] = \\underbrace{\\begin{bmatrix}\n",
    "W_N^0 & W_N^0 & \\cdots & W_N^0 \\\\\n",
    "W_N^0 & W_N^1 & \\cdots & W_N^{N-1}\\\\\n",
    "\\vdots &  \\vdots & \\ddots & \\vdots\\\\\n",
    "W_N^0 & W_N^{N-1} & \\cdots & W_N^{(N-1)(N-1)}\n",
    "\\end{bmatrix}}_{\\mathbf{W}}\n",
    "\\underbrace{\\begin{bmatrix}\n",
    "x[0] \\\\\n",
    "x[1] \\\\\n",
    "\\vdots \\\\\n",
    "x[N-1] \\\\\n",
    "\\end{bmatrix}}_{\\vec{x}} = \n",
    "\\begin{bmatrix}\n",
    "\\langle W_N^{-0*n},\\vec{x} \\rangle\\\\\n",
    "\\langle W_N^{-1*n},\\vec{x} \\rangle\\\\\n",
    "\\vdots\\\\\n",
    "\\langle W_N^{-k*n},\\vec{x} \\rangle\\\\\n",
    "\\vdots\\\\\n",
    "\\langle W_N^{-(N-1)*n},\\vec{x} \\rangle\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In the above $\\textbf{W}$ matrix, each row represents a frequency vector rotating at a certain frequency. More concretely, row $k$ in $\\mathbf{W}$ represents the frequency vector rotating with frequency $\\omega_k=\\frac{2\\pi}{N}k$. This kind of intuition is powerful in signal processing. If this confuses or (hopefully not) scares you, do not worry! It takes time to be comfortable with combining signal processing and linear algebra. Read the above explanation a couple times, ask your TA questions, check out your textbook's coverage of this, or hang out with some friends and chat about it!\n",
    "\n",
    "### And finally the FFT!\n",
    "\n",
    "We will not focus on the math of the FFT since you have covered it in ECE 310. For now, we should acknowledge the computational efficiency of the FFT. The previous two views of the DFT we have discussed - summation and vectorized versions - all require $\\mathcal{O}(n^2)$ multiply-add operations. Conversely, the FFT is a divide-and-conquer algorithm that can perform the same computation in $\\mathcal{O}(n\\log n)$ multiply-add operations. Keep this in mind when completing Excercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio\n",
    "from skimage.io import imread\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from linear_convolution import linear_convolution\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1: Implementing the DFT\n",
    "\n",
    "There are multiple different implementations we can use to represent the DFT. In this exercise, you will compare three ways to compute the DFT. \n",
    "\n",
    "a. First, fill in the below function $\\textrm{dfl_dft()}$ to create a double for-loop implementation of the DFT. Hint: this will work a lot like your DTFT function from Lab 4!\n",
    "\n",
    "b. Next, fill in $\\textrm{dft_matrix()}$ and $\\textrm{vectorized_dft()}$ to create a vectorized implementation of the DFT.\n",
    "\n",
    "c. Finally, let's test our double for-loop and vectorized methods against the $\\textrm{np.fft.fft()}$ implementation. Run the provided code that benchmarks the running time of eahc method and verifies if your methods accurately compute the DFT of a randomly generated signal. Note that we do not benchmark the time to build the $\\mathbf{W}$ matrix since this could be precomputed in a practical context. For example, if we compute 1000 length-500 DFTs, we would only need to construct \"W\" once. Comment on the results. Which method is fastest? Slowest? Why? Does anything surprise you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to complete for 1.a\n",
    "def dfl_dft(x):\n",
    "    N = len(x)\n",
    "    dft = np.zeros(N, dtype=np.complex64)\n",
    "    #for loop to iterate over 'k'\n",
    "\n",
    "    #for loop to iterate over 'n'\n",
    "\n",
    "    return dft\n",
    "\n",
    "#Functions to complete for 1.b\n",
    "#Construct the matrix W\n",
    "def dft_matrix(N):\n",
    "    W = np.zeros((N, N),dtype=np.complex64)\n",
    "    #fill in W however you see fit!\n",
    "\n",
    "    return W\n",
    "#Take the DFT of signal x using the matrix W\n",
    "def vectorized_dft(W, x):\n",
    "    #this should only take one line...\n",
    "    #refer to the above math if you are unsure!\n",
    "    dft = None\n",
    "    return dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provided code for 1.c\n",
    "#Generate test signal\n",
    "N = 500\n",
    "x = np.random.uniform(size=N)\n",
    "\n",
    "#Test double for-loop implementation\n",
    "print('Double For Loop Time:')\n",
    "%timeit dfl_dft(x)\n",
    "print('')\n",
    "\n",
    "#Test vectorized implementation\n",
    "#don't time W matrix construction since this is precomputation that could be practically stored\n",
    "W = dft_matrix(N)\n",
    "print('Vectorized Time')\n",
    "%timeit vectorized_dft(W,x)\n",
    "print('')\n",
    "\n",
    "#Test numpy's fft implementation\n",
    "print('Numpy Time')\n",
    "%timeit np.fft.fft(x)\n",
    "print('')\n",
    "\n",
    "#Test if results are equivalent\n",
    "print('Double for-loop and numpy fft are equivalent:',np.allclose(dfl_dft(x),np.fft.fft(x)))\n",
    "print('Vectorized DFT and numpy fft are equivalent:',np.allclose(vectorized_dft(W,x),np.fft.fft(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for Part 1.c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowing and Zero-Padding\n",
    "\n",
    "We will now briefly discuss the motivation for windowing and zero-padding. Exercises 2 and 3 will demonstrate and reinforce this theory.\n",
    "\n",
    "Recall that the DFT works under the practical assumption that we only have a finite number of samples for our signal. Unlike the DTFT which uses infinitely points, we must use a finite collection to capture the frequency content of our signal. In the simplest case, we use a rectangular window that removes the $N$ points of our signal we would like to inspect for the DFT. Mathematically, we have,\n",
    "\n",
    "$$\n",
    "x_{\\textrm{windowed}} = x[n](u[n-n_0]-u[n-(n_0+N)]),\n",
    "$$\n",
    "\n",
    "where $n_0$ is the start-point of our signal's window. This window signal is the same as a shifted rectangle function. We see that windowing is multiplying in the time domain, which by convolution theory must correspond to multiplication in the frequency domain. Thus, for a window function $w[n]$,\n",
    "\n",
    "$$\n",
    "x[n]w[n] \\stackrel{\\mathcal{F}}{\\leftrightarrow} \\frac{1}{2\\pi}X(\\omega) * W(\\omega).\n",
    "$$\n",
    "\n",
    "Exercise 2 will explore the consequences of using the rectangular window and what other windows may be used. Next, let's explain the use of zero-padding. When zero-padding a signal, we are simply appending some number of zeros to the end of the original signal. What effect does this have? Suppose I have original signal $x[n]$ of length $N$ and a zero-padded signal $x_{zp}[n]$ of length $M>N$ that has been padded with $M-N$ zeros.\n",
    "\n",
    "\\begin{align*}\n",
    "X[k] &= \\sum_{n=0}^{N-1}x[n]e^{-j\\frac{2\\pi k}{N}n},\\quad 0\\leq k\\leq N-1\n",
    "\\\\X_{zp}[k] &= \\sum_{n=0}^{M-1}x_{zp}[n]e^{-j\\frac{2\\pi k}{M}n},\\quad 0\\leq k\\leq M-1\n",
    "\\\\x_{zp}[n] = 0\\textrm{ for all } n \\geq N \\implies X_{zp}[k] &= \\sum_{n=0}^{N-1}x_{zp}[n]e^{-j\\frac{2\\pi k}{M}n}\n",
    "\\\\X_{zp}[k] &= \\sum_{n=0}^{N-1}x[n]e^{-j\\frac{2\\pi k}{M}n},\\quad 0\\leq n\\leq M-1\n",
    "\\end{align*}\n",
    "We see that the zero-padded signal's DFT will use the exact same signal values, and thus have the exact same frequency content. The difference is that the spacing of our frequency sampling is tighter!\n",
    "\n",
    "$$\n",
    "\\frac{2\\pi}{M} < \\frac{2\\pi}{N}\n",
    "$$\n",
    "\n",
    "Consequently, we add no \"information\" to our signal (only zeros) and gain higher frequency resolution at the cost of storing some zeros. This is what implictly happens when you use $\\textrm{np.fft.fft()}$ or $\\textrm{np.fft.rfft()}$ and specify a number of points greater than the length of the signal. Exercise 3 will give a brief example of how zero-padding can affect our ability to resolve different frequency components or notes in audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2: Windowing Effects\n",
    "\n",
    "In this exercise, we want to investigate the effects of different windowing methods. When we are computing the DFT of a finite-length signal, it is assumed that there is periodic extension of this finite segment (more on this in Exercise 5 and related background). If the segment precisely captures full cycles of all the frequencies, then there will be no problem since we have no periodic interruptions and the transition between periodic copies of the signal will be seamless. However, if the segment does not capture full cycles of some frequencies, then there will be periodic interruptions or discontinuities as the signal is periodically extended. This can lead to changes in our ideal frequency content. This problem is referred to as spectral leakage. This is illustrated in the example below:\n",
    "\n",
    "Suppose that we are sampling a single sine wave, consider the two cases we have discussed:\n",
    "1. We sample a window of the signal that perfectly captures an integer number of signal periods.\n",
    "2. We sample a window of the signal that captures a fractional number of signal periods.\n",
    "\n",
    "Below, our ideal signal is $\\sin\\left(\\frac{\\pi}{4}n\\right)$. Thus, we need eight points to capture a full period of the signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make longer signal that we will window in order to analyze a smaller portion\n",
    "x = np.array([np.sin(np.pi/4*n) for n in range(200)])\n",
    "# Case 1 \n",
    "N1 = 80 #10 full periods\n",
    "x1 = x[:N1]\n",
    "x1_fft = np.fft.rfft(x1)\n",
    "omega_1 = np.linspace(0,np.pi,len(x1_fft))\n",
    "\n",
    "# case 2\n",
    "N2 = 78 # 7 full period and one fractional period\n",
    "x2 = x[:N2]\n",
    "x2_fft = np.fft.rfft(x2)\n",
    "omega_2 = np.linspace(0,np.pi,len(x2_fft))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.stem(x1)\n",
    "plt.title('Case 1 Signal')\n",
    "plt.subplot(122)\n",
    "plt.stem(x2)\n",
    "plt.title('Case 2 Signal')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(121)\n",
    "plt.stem(omega_1, abs(x1_fft))\n",
    "plt.title('FFT for Case 1')\n",
    "plt.xlabel('$\\omega$')\n",
    "plt.subplot(122)\n",
    "plt.stem(omega_2, abs(x2_fft))\n",
    "plt.title('FFT for case 2')\n",
    "plt.xlabel('$\\omega$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example, we can see that although we are sampling the same sine wave signal, we obtain different frequency spectra for the two cases. The mismatch in sampling length for case 2 leads to the spectral leakage witnessed above. Notice how the main peak at $\\frac{\\pi}{4}$ is lower in case 2 since the energy of this frequency has spread out to adjacent frequencies. Recall that the mismatch in sampling size creates a discontinuity between the periodically extended copies of our finite window. This introduces other frequencies into the spectrum to compensate for this discontinuity. In practice, spectral leakage is unavoidable since many real-world signals have much richer frequency content. This is where windowing comes in.\n",
    "\n",
    "We would like windowing to smooth out the discontinuity and decrease the impact of spectral leakage. There are a many possible windows we may consider, but we will restrict ourselves to examining the following three:\n",
    "\n",
    "1. Rectangular or Boxcar Window\n",
    "2. Hamming Window\n",
    "3. Kaiser ($\\beta=3$)\n",
    "\n",
    "a. Plot the time domain representation of each of these windows (using the ``N2=78`` from above). Hint: use $\\textrm{scipy.signal.hamming()}$ and $\\textrm{scipy.signal.kaiser()}$.\n",
    "\n",
    "b. Plot the magnitude spectrum of each window on the same plot on a dB scale. **Please specify 512 points and use $\\textrm{np.fft.rfft()}$**. You may use $\\textrm{plt.plot()}$ instead of $\\textrm{plt.stem()}$ since we have many points here. We have provided a function $\\textrm{sig2db}$ that converts a magnitude response to dB scale. Comment on the differences in the magnitude spectrum of each window.\n",
    "\n",
    "c. Apply each window to the sine wave signal we sampled with a fractional number of periods (``x2``) and plot the magnitude spectrum of each windowed result. Comment on the resulting spectra. How do the main lobe widths and side lobe heights of the sinusoid's peak differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2 = 78 # number of points we use to create our window\n",
    "x2 = x[:N2]\n",
    "# quick function for converting a magnitude response to dB\n",
    "def sig2db(mag_spec):\n",
    "    return 20*np.log10(mag_spec)\n",
    "\n",
    "\n",
    "#Code for 2.a:\n",
    "\n",
    "\n",
    "#Code for 2.b:\n",
    "\n",
    "\n",
    "#Code for 2.c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for part 2.b:\n",
    "\n",
    "\n",
    "Comments for part 2.c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Zero-Padding00000\n",
    "\n",
    "Now let's consider the problem of examining frequency content in a piece of music and how zero-padding affects our ability to do so. Load and listen to the below audio clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, music_stereo = wavfile.read('Hallelujah_16k.wav') # Import the sound file\n",
    "music_mono = music_stereo[:,0] # To obtain mono sound track\n",
    "Audio(music_mono, rate = fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot going on for such a short audio clip! What if we only look at the frequency content present in the first 256 samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 256\n",
    "music_mono_short = music_mono[:N] # if we are only given the first 256 samples\n",
    "fft_short = np.fft.rfft(music_mono_short)\n",
    "omega = np.linspace(0,np.pi,len(fft_short)) \n",
    "plt.figure(figsize =(10,6))\n",
    "plt.plot(omega, abs(fft_short))\n",
    "plt.title('DFT for length-256 audio signal')\n",
    "plt.xlabel(r'$\\omega$')\n",
    "plt.ylabel('Magnitude Response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Zero-pad our length-256 clip to length 2048. Plot the new magnitude spectrum of our zero-padded signal.\n",
    "\n",
    "b. Comment on the differences (quantitative or qualitative) that you observe. Has zero-padding improved our ability to distinguish different frequencies?\n",
    "\n",
    "c. Now, if we are only given the first 16 samples instead of 256. Do you think zero-padding to length 2048 will also give us the ability to identify all the peaks like in the previous case? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 3a:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for 3b:\n",
    "\n",
    "\n",
    "Comments for 3c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Spectrograms\n",
    "\n",
    "Now let's look at the spectrogram for an audio signal. A spectrogram can be thought of as a two-dimensional signal with both time and frequency axes. Thus, the value of a spectrogram at a particular pair of time and frequency indicates how much energy we have of that frequency at the given time. Let visualize some examples to make this more concrete. Specifically, we have three audio files that contain three different speech sounds or utterances.\n",
    "\n",
    "* Vowel \"a\": specifically, we hear the sound \"ah\"\n",
    "* Consonant \"r\": speaker repeats the sound \"rah\"\n",
    "* Constant \"b\": speaker repeats the sound \"bah\"\n",
    "\n",
    "Let's listen to them and visualize their spectrograms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_a, vowel_a = wavfile.read('a.wav') \n",
    "fs_r, cons_r = wavfile.read('r.wav') \n",
    "fs_b, cons_b = wavfile.read('b.wav') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(vowel_a, rate = fs_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(cons_r, rate = fs_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(cons_b, rate = fs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfft = 512\n",
    "f_a, t_a, S_a = signal.spectrogram(vowel_a, fs_a, nperseg = nfft, noverlap = int(nfft/2), nfft = nfft)\n",
    "f_r, t_r, S_r = signal.spectrogram(cons_r, fs_r, nperseg = nfft, noverlap = int(nfft/2), nfft = nfft)\n",
    "f_b, t_b, S_b = signal.spectrogram(cons_b, fs_b, nperseg = nfft, noverlap = int(nfft/2), nfft = nfft)\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(131)\n",
    "plt.pcolormesh(t_a, f_a, sig2db(S_a))\n",
    "plt.title('Spectrogram for \"a\"')\n",
    "plt.ylim([0, 3000])\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.colorbar()\n",
    "plt.subplot(132)\n",
    "plt.pcolormesh(t_r, f_r, sig2db(S_r))\n",
    "plt.title('Spectrogram for \"r\"')\n",
    "plt.ylim([0, 4000])\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.colorbar()\n",
    "plt.subplot(133)\n",
    "plt.pcolormesh(t_b, f_b, sig2db(S_b))\n",
    "plt.title('Spectrogram for \"b\"')\n",
    "plt.ylim([0, 3000])\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Comment on the differences in the the above spectrograms. Which utterances have higher frequency content? Which have lower frequency content? Try thinking about the pitch of your voice when forming these sounds. Remember that the \"r\" and \"b\" clips both have the \"ah\" sound of the first clip, so some frequency content will be shared between all three clips\n",
    "\n",
    "b. We have included a sound file ``robot.wav`` in the lab folder. This file contains a person saying the word \"robot\". Load the sound file and plot its spectrogram. Refer to the above spectrogram examples and the $\\textrm{signal.spectrogram()}$ documentation if you are unsure how to do this.\n",
    "\n",
    "c. We know that this word contains the two consonants \"r\" and \"b\". From the example spectrograms provided above, can you tell where these consonants appear in the word's spectrogram (i.e. what time do they start)? If so, where do the consonants \"r\" and \"b\" begin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for 4.b here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for 4.a here:\n",
    "\n",
    "\n",
    "Comments for 4.c here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular Convolution and Related DFT Properties\n",
    "\n",
    "A key assumption in the computation of the DFT is the periodic extension of the signal in the time domain. This periodicity also relates to the $2\\pi$ periodicity of the DTFT and DFT.\n",
    "\n",
    "$$\n",
    "x[n] = x[n+N], \\quad \\forall k\n",
    "$$\n",
    "\n",
    "$$\n",
    "X[k] = X[k+N], \\quad \\forall k\n",
    "$$\n",
    "\n",
    "Please refer to the ECE 310 textbook for further mathematical background here. The important takeaway here is that any shifts in time must be circular. Consequently, the convolution that is induced in the time domain by multiplication in the DFT domain is circular. More concisely, multiplication in the DFT domain is circular convolution in the time domain. Thus, for a signal $x[n]$ and system $h[n]$ with DFTs $X[k]$ and $H[k]$, respectively, we have:\n",
    "\n",
    "$$\n",
    "X[k]H[k] \\implies \\sum_{n = 0}^{N-1}x[m-n]_Nh[m] = \\sum_{n=0}^{N-1}x[m]h[m-n]_N,\n",
    "$$\n",
    "\n",
    "where $[k]_N \\equiv (k \\mod N)$. Notice that circular convolution between two sequences produces a very different result from the ordinary linear convolution. Thus, we must be careful to make the circular convolution we perform equivalent to the linear convolution of the two sequences. This will guarantee that multiplying in the DFT domain will produce a result consistent with multiplication in the DTFT domain. How do we accomplish this? With zero-padding!\n",
    "\n",
    "Recall that the linear convolution between length $L$ and length $M$ sequences lead to a length $L+M-1$ result. Conversely, the circular convolution of these sequences would be of length $\\max\\{L,M\\}$; although, the two sequences are typically the same length by convention. Intuitively, if we want our circular conovlution to be the same as our linear convolution, we should guarantee the result is of length $L+M-1$. And this will work! In order to make our circular convolution equivalent to the linear convolution result, we do the following:\n",
    "\n",
    "$$\n",
    "\\textrm{length}(x) = L,\\quad \\textrm{length}(h) = M\n",
    "$$\n",
    "\n",
    "$$\n",
    "x\\implies \\textrm{pad }M-1\\textrm{ zeros}\n",
    "$$\n",
    "$$\n",
    "h\\implies \\textrm{pad }L-1\\textrm{ zeros}.\n",
    "$$\n",
    "\n",
    "This procedure will guarantee our convolution is the correct length and will also prevent aliasing due to the circular modulation of the shifting sequence. Now, why are we concerned with using the DFT and bothering with circular convolution? Consider that linearly convolving two sequences requires $\\mathcal{O}(n^2)$ multiply-add operations. On the other hand, computing the DFT via the FFT takes $\\mathcal{O}(n\\log n)$ operations. Thus, if we take the DFT of both our signal and filter, multiply in the DFT domain, and perform the inverse DFT via the IFFT, we will have the following computational complexity:\n",
    "\n",
    "$$\n",
    "\\underbrace{\\mathcal{O}(n\\log n) + \\mathcal{O}(n\\log n)}_{\\textrm{DFT of signal/filter}} + \\underbrace{\\mathcal{O}(n)}_{X[k]H[k]} + \\underbrace{\\mathcal{O}(n\\log n)}_{\\textrm{Inverse DFT}} = \\mathcal{O}(3n\\log n) + \\mathcal{O}(n) \\implies \\mathcal{O}(n\\log n).\n",
    "$$\n",
    "\n",
    "These computational savings are especially impressive when $n$ becomes large for something like an audio signal. Thus, we can use the DFT to perform fast linear convolution for our LSI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Fast Linear Convolution\n",
    "\n",
    "In this exercise, you will create your own implementation of fast linear convolution via the DFT.  \n",
    "\n",
    "a. Fill in the function $\\textrm{fast_convolution()}$ to implement fast linear convolution via the DFT. Refer to the above background if you need help with the necessary steps. Verify the results of your function against $\\textrm{signal.convolve()}$ with the provided sample input and filter by printing the output of your function and $\\textrm{signal.convolve()}$. Hint: use $\\textrm{np.fft.ifft()}$ to take the inverse DFT.\n",
    "\n",
    "Next, we want to compare the running time of your fast linear convolution function against regular linear convolution via summation. Unfortunately, numpy and scipy's implementations of convolution via summation are too efficient (likely written in C code via Cython) to be compared against our fast convolution. As such, we have provided a function for you called $\\textrm{linear_convolution(x1,x2)}$ that implements convolution by summation in Python. This will be a fairer test of the efficiency of your fast linear convolution function.\n",
    "\n",
    "We have provided a testing framework that builds a random signal and filter of length $L$, calls your function and the linear convolution function, and outputs the running time.\n",
    "\n",
    "b. Test the two functions for $L = 2^6$. Report the average running time in the below Markdown cell.\n",
    "\n",
    "c. Test the two functions for $L = 2^{10}$. Report the average running time.\n",
    "\n",
    "d. Test the two functions for $L = 2^{14}$. Report the average running time. (You may use $2^{12}$ or $2^{13}$ here if your laptop does not have enough memory for such large sequences.)\n",
    "\n",
    "e. Comment on the results for each length. How do your results compare to the theoretical background given above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for 5.a:\n",
    "\n",
    "#Fill in this function!\n",
    "def fast_convolution(x,h):\n",
    "    \n",
    "    return y\n",
    "\n",
    "#Test signals\n",
    "x1 = [1,3,-2,-1]\n",
    "x2 = [0,2,4,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing framework for parts 5.b-5.d:\n",
    "L = ??? #Change this for each part!\n",
    "x = np.random.uniform(size=L)\n",
    "h = np.random.uniform(size=L)\n",
    "print('Regular Linear Convolution Results:')\n",
    "%timeit linear_convolution(x,h)\n",
    "print('Fast Linear Convolution Results:')\n",
    "%timeit fast_convolution(x,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for 5.b:\n",
    "\n",
    "\n",
    "Results for 5.c:\n",
    "\n",
    "\n",
    "Results for 5.d:\n",
    "\n",
    "\n",
    "Comments for 5.e:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Where's Waldo Going?\n",
    "\n",
    "We will conclude this lab with an interesting (and cute) demonstration of DFT properties. The notion of the DFT is not limited to one-dimensional signals: we may go to arbitrary numbers of dimensions. For this exercise, we will work with the (two-dimensional) DFT of an image. We have provided the DFT of the test image.\n",
    "\n",
    "a. For this part, we will apply a linear phase to each row of the image's DFT. Mathematically, this means you will multiply each row $r$ in the image's DFT by the following complex number\n",
    "\n",
    "$$\n",
    "\\large{\\textrm{Phase at row }r = e^{-j\\frac{2\\pi n_0}{R} r}},\n",
    "$$\n",
    "\n",
    "where $R$ is the number of rows in the image and $n_0$ is the phase offset we would like. Notice that each row is multiplied by its own constant complex number. This phase scales linearly from row-to-row. Apply linear phase along the rows of the test image for $n_0=100$. Take the inverse two-dimensional DFT of the resulting DFT and plot the real part of the resulting image. (Hint: use $\\textrm{np.fft.ifft2()}$ and $\\textrm{np.real()}$ here.) \n",
    "\n",
    "b. Apply linear phase to each column of the image's DFT for $n_0 = 100$. Take the inverse two-dimensional DFT of the resulting DFT and plot the real part of the resulting image. Note that you should divide by the number of columns in the above complex exponential for this case.\n",
    "\n",
    "c. Apply linear phase to the rows and columns of the image's DFT. You may apply the phase along the rows then columns or columns then rows. Choose any non-zero offsets for the rows and columns, respectively.\n",
    "\n",
    "d. Describe what is happening in the previous three parts. Why is this happening? Think about the DFT properties!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and plot original image\n",
    "img = imread('test-image.jpg')\n",
    "n_rows = img.shape[0]\n",
    "n_cols = img.shape[1]\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.imshow(img,'gray')\n",
    "plt.title('Original Image')\n",
    "\n",
    "#Compute 2D-DFT\n",
    "fft2 = np.fft.fft2(img)\n",
    "\n",
    "#Code for part 6.a:\n",
    "\n",
    "\n",
    "#Code for part 6.b:\n",
    "\n",
    "\n",
    "#Code for part 6.c:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for part 6.d:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "Please rename this notebook to \"netid_Lab5\" and submit a zip file including all the supplied files for this lab to Compass. Please also name your zip file submission \"netid_Lab5\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
